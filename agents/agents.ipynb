{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea19fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from wikipedia) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: arxiv in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from arxiv) (2.32.4)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchainhub in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from langchainhub) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from langchainhub) (2.32.4)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from langchainhub) (2.32.4.20250611)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wikipedia\n",
    "%pip install arxiv\n",
    "%pip install langchainhub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ce2e53",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa369c",
   "metadata": {},
   "source": [
    "## Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab868308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9ef539",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d3f1c",
   "metadata": {},
   "source": [
    "## Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# loader = WebBaseLoader(web_paths=[\"https://docs.smith.langchain.com/\"]) #EXTRACT\n",
    "\n",
    "# docs = loader.load() # LOAD\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs) # SPLIT\n",
    "\n",
    "# db = FAISS.from_documents(text_splitter[:10], embedding=OllamaEmbeddings(model=\"llama3\")) # EMBED\n",
    "\n",
    "# retriever = db.as_retriever() # RETRIEVE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff83e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretriever\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_retriever_tool\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m retriever_tool = create_retriever_tool(\u001b[43mretriever\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mlangsmith_search\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSearch for information about langsmith. For any question about langsmith, use this tool to answer.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# retriever_tool = create_retriever_tool(retriever, \"langsmith_search\", \"Search for information about langsmith. For any question about langsmith, use this tool to answer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e71df2",
   "metadata": {},
   "source": [
    "## Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1c9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d48213",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool, arxiv_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb46c0",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81dc883",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8518c726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"C:/Users/Lenovo/Desktop/LANGCHAIN/.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fed12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae72d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec2a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. You have access to a set of tools to answer user questions. Choose the best tool for the job.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc85e08",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fcd4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8378dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b35d566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Tesla CEO'}`\n",
      "responded: [{'text': \"To answer this question accurately, I'll need to look up the most current information about Tesla's leadership. Let me use the Wikipedia tool to find this information for you.\", 'type': 'text', 'index': 0}, {'id': 'toolu_01LJZFAsRRysN2rMbvVWWVWS', 'input': {}, 'name': 'wikipedia', 'type': 'tool_use', 'index': 1, 'partial_json': '{\"query\": \"Tesla CEO\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Tesla, Inc.\n",
      "Summary: Tesla, Inc. ( TEZ-lə or   TESS-lə) is an American multinational automotive and clean energy company. Headquartered in Austin, Texas, it designs, manufactures and sells batte\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Elon Musk Tesla CEO'}`\n",
      "responded: [{'text': \"I apologize, but the summary provided doesn't contain the specific information we're looking for. Let me try a more direct search query to find the CEO of Tesla.\", 'type': 'text', 'index': 0}, {'id': 'toolu_011yC122Z1nk18kkwzFd7rGg', 'input': {}, 'name': 'wikipedia', 'type': 'tool_use', 'index': 1, 'partial_json': '{\"query\": \"Elon Musk Tesla CEO\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Wealth of Elon Musk\n",
      "Summary: Elon Musk is the wealthiest person in the world, with an estimated net worth of US$381 billion as of May 2025, according to the Bloomberg Billionaires Index, and $42\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Tesla company leadership'}`\n",
      "responded: [{'text': \"I apologize, but the information provided still doesn't directly answer our question. Let me try one more time with a different approach.\", 'type': 'text', 'index': 0}, {'id': 'toolu_01HpTx3E2obU6neCQrTQJTg5', 'input': {}, 'name': 'wikipedia', 'type': 'tool_use', 'index': 1, 'partial_json': '{\"query\": \"Tesla company leadership\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Tesla, Inc.\n",
      "Summary: Tesla, Inc. ( TEZ-lə or   TESS-lə) is an American multinational automotive and clean energy company. Headquartered in Austin, Texas, it designs, manufactures and sells batte\u001b[0m\u001b[32;1m\u001b[1;3m[{'text': \"I apologize for the difficulty in finding the specific information. Based on the search results and my knowledge, I can provide you with the answer:\\n\\nThe CEO of Tesla is Elon Musk.\\n\\nElon Musk has been the CEO of Tesla since 2008. He co-founded the company and has been a driving force behind its growth and innovation in the electric vehicle and clean energy sectors. While the Wikipedia tool didn't provide us with a direct statement about his current role, it's well-established that Elon Musk continues to serve as the CEO of Tesla.\\n\\nIf you need any more specific or up-to-date information about Tesla's leadership, please let me know, and I'll be happy to search for it.\", 'type': 'text', 'index': 0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response2 = agent_executor.invoke({\n",
    "    \"input\": \"Who is the CEO of Tesla?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2e5919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is the CEO of Tesla?',\n",
       " 'output': [{'text': \"I apologize for the difficulty in finding the specific information. Based on the search results and my knowledge, I can provide you with the answer:\\n\\nThe CEO of Tesla is Elon Musk.\\n\\nElon Musk has been the CEO of Tesla since 2008. He co-founded the company and has been a driving force behind its growth and innovation in the electric vehicle and clean energy sectors. While the Wikipedia tool didn't provide us with a direct statement about his current role, it's well-established that Elon Musk continues to serve as the CEO of Tesla.\\n\\nIf you need any more specific or up-to-date information about Tesla's leadership, please let me know, and I'll be happy to search for it.\",\n",
       "   'type': 'text',\n",
       "   'index': 0}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3055d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks'}`\n",
      "responded: [{'text': \"To answer this question, I'll need to search for information about this specific research paper. The arxiv tool would be most appropriate for this query since it's related to a scientific article in the field of Computer Science. Let me search for this paper.\", 'type': 'text', 'index': 0}, {'id': 'toolu_01KgWHUvojbimdgeTaaWzi28', 'input': {}, 'name': 'arxiv', 'type': 'tool_use', 'index': 1, 'partial_json': '{\"query\": \"BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2022-06-19\n",
      "Title: Resource-Constrained Edge AI with Early Exit Prediction\n",
      "Authors: Rongkang Dong, Yuyi Mao, Jun Zhang\n",
      "Summary: By leveraging the data sample diversity, the early-exit networ\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '\"BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\" authors'}`\n",
      "responded: [{'text': \"I apologize, but it seems the arxiv search didn't return the exact paper we're looking for. The search result is for a different paper with a similar topic. Let me try a more specific search query.\", 'type': 'text', 'index': 0}, {'id': 'toolu_016EiMng4QfovJo9x2WdX9dB', 'input': {}, 'name': 'arxiv', 'type': 'tool_use', 'index': 1, 'partial_json': '{\"query\": \"\\\\\"BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\\\\\" authors\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2017-09-06\n",
      "Title: BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\n",
      "Authors: Surat Teerapittayanon, Bradley McDanel, H. T. Kung\n",
      "Summary: Deep neural networks are state \u001b[0m\u001b[32;1m\u001b[1;3m[{'text': 'Great! I\\'ve found the correct paper. Now I can answer your question.\\n\\nThe authors of the research paper \"BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\" are:\\n\\n1. Surat Teerapittayanon\\n2. Bradley McDanel\\n3. H. T. Kung\\n\\nThis paper was published on September 6, 2017, according to the arxiv search results.', 'type': 'text', 'index': 0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response3 = agent_executor.invoke({\n",
    "    \"input\": \"Who are the authors of the 'BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks' research paper?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b957e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Great! I\\'ve found the correct paper. Now I can answer your question.\\n\\nThe authors of the research paper \"BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\" are:\\n\\n1. Surat Teerapittayanon\\n2. Bradley McDanel\\n3. H. T. Kung\\n\\nThis paper was published on September 6, 2017, according to the arxiv search results.',\n",
       "  'type': 'text',\n",
       "  'index': 0}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58034fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'BranchyNet'}`\n",
      "responded: [{'text': \"To answer this question accurately, we'll need to search for scientific articles related to the BranchyNet architecture. The best tool for this purpose is the arxiv function, which allows us to search for research papers in various scientific fields, including Computer Science.\\n\\nLet's use the arxiv tool to search for papers mentioning BranchyNet:\", 'type': 'text', 'index': 0}, {'id': 'toolu_016NV4AgygdYTctURa7Z9Aqu', 'input': {}, 'name': 'arxiv', 'type': 'tool_use', 'index': 1, 'partial_json': '{\"query\": \"BranchyNet\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2017-09-06\n",
      "Title: BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\n",
      "Authors: Surat Teerapittayanon, Bradley McDanel, H. T. Kung\n",
      "Summary: Deep neural networks are state \u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '\"BranchyNet\" OR \"Branchy Net\"'}`\n",
      "responded: [{'text': 'Based on the search results, we can see that there is at least one paper directly related to BranchyNet:\\n\\n\"BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\" by Surat Teerapittayanon, Bradley McDanel, and H. T. Kung, published on 2017-09-06.\\n\\nHowever, this result doesn\\'t give us the full picture of how many research papers are based on the BranchyNet architecture. The arxiv search only shows us the most relevant result, which is likely the original paper introducing BranchyNet.\\n\\nTo get a more accurate count of research papers based on BranchyNet, we would need to:\\n\\n1. Perform a broader search that includes papers citing or building upon the original BranchyNet paper.\\n2. Search other academic databases beyond arXiv, such as Google Scholar, IEEE Xplore, or ACM Digital Library.\\n\\nUnfortunately, we don\\'t have direct access to these broader search capabilities through the available tools. However, we can try to refine our search on arXiv to get a better idea:', 'type': 'text', 'index': 0}, {'id': 'toolu_01MAm9bKQEKhhxnkxyMGJwdb', 'input': {}, 'name': 'arxiv', 'type': 'tool_use', 'index': 1, 'partial_json': '{\"query\": \"\\\\\"BranchyNet\\\\\" OR \\\\\"Branchy Net\\\\\"\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2017-09-06\n",
      "Title: BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\n",
      "Authors: Surat Teerapittayanon, Bradley McDanel, H. T. Kung\n",
      "Summary: Deep neural networks are state \u001b[0m\u001b[32;1m\u001b[1;3m[{'text': 'The results still show only the original paper, which suggests that arXiv might not have many papers directly mentioning BranchyNet in their title or abstract.\\n\\nGiven the limitations of our search capabilities, I can\\'t provide an exact number of research papers based on the BranchyNet architecture. However, we can conclude that:\\n\\n1. There is at least one seminal paper introducing BranchyNet, published in 2017.\\n2. The concept might be referenced or built upon in other papers without explicitly mentioning \"BranchyNet\" in their title or abstract, which makes them harder to find with our current tools.\\n3. To get a comprehensive count, one would need to perform a citation analysis and a broader literature review across multiple academic databases.\\n\\nIf you need a more precise count or information about follow-up research, I would recommend:\\n\\n1. Checking citation databases to see how many times the original BranchyNet paper has been cited.\\n2. Searching for terms related to the concept of BranchyNet, such as \"early exiting neural networks\" or \"adaptive neural network inference.\"\\n3. Consulting with a librarian or using more comprehensive academic search tools that can perform in-depth literature reviews.', 'type': 'text', 'index': 0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response4 = agent_executor.invoke({\n",
    "    \"input\": \"How many research papers are based on the BranchyNet architecture?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bd3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
